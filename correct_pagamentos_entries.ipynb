{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data from the CSV files\n",
    "base_info = pd.read_csv('base_info.csv')\n",
    "base_pagamentos = pd.read_csv('base_pagamentos_desenvolvimento.csv')\n",
    "base_cadastral = pd.read_csv('base_cadastral.csv')\n",
    "\n",
    "# lower case all column names\n",
    "base_info.columns = base_info.columns.str.lower()\n",
    "base_pagamentos.columns = base_pagamentos.columns.str.lower()\n",
    "base_cadastral.columns = base_cadastral.columns.str.lower()\n",
    "\n",
    "# convert str to date\n",
    "def convert_date(df, to_date_columns, format):\n",
    "  df_copy = df.copy()\n",
    "  for col in to_date_columns:\n",
    "    df_copy[col] = pd.to_datetime(df_copy[col], format=format).dt.date\n",
    "  return df_copy\n",
    "\n",
    "date_columns = ['data_emissao_documento', 'data_pagamento', 'data_vencimento']\n",
    "base_pagamentos_date = convert_date(base_pagamentos, date_columns, '%Y-%m-%d')\n",
    "base_pagamentos_date = convert_date(base_pagamentos_date, ['safra_ref'], '%Y-%m')\n",
    "base_info_date = convert_date(base_info, ['safra_ref'], '%Y-%m')\n",
    "base_cadastral_date = convert_date(base_cadastral, ['data_cadastro'], '%Y-%m-%d')\n",
    "\n",
    "# ajust values in base_cadastral\n",
    "base_cadastral.flag_pf = (base_cadastral.flag_pf == 'X').astype(int)\n",
    "base_cadastral.segmento_industrial = base_cadastral.segmento_industrial.fillna('NAN')\n",
    "base_cadastral.dominio_email = base_cadastral.dominio_email.fillna('NAN')\n",
    "base_cadastral.porte = base_cadastral.porte.fillna('NAN')\n",
    "base_cadastral.cep_2_dig = base_cadastral.cep_2_dig.fillna('NA')\n",
    "base_cadastral.ddd = base_cadastral.ddd.fillna('-1')\n",
    "base_cadastral[base_cadastral.ddd.str.contains(\"\\(\")] = '-2'\n",
    "\n",
    "# Add a binary column, fraud, to base_pagamentos_desenvolvimento_coherent and assing 1 to rows where DATA_PAGAMENTO > DATA_VENCIMENTO + 5\n",
    "base_pagamentos_date['late_payment'] = (base_pagamentos_date['data_pagamento'] - base_pagamentos_date['data_vencimento']).dt.days\n",
    "base_pagamentos_date['fraud'] = np.where(base_pagamentos_date['late_payment'] > 5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fraud_dependent_of_the_data_exclusive_to_pagamentos_table(info, pagamentos):\n",
    "  info = info.copy()\n",
    "  pagamentos = pagamentos.copy()\n",
    "\n",
    "  # lable as 1 all rows of pagamentos where the pair (id_cliente, safra_ref) is in info and as 0 otherwise\n",
    "  pagamentos['id_cliente_safra_ref'] = pagamentos['id_cliente'].astype(str) + '_' + pagamentos['safra_ref'].astype(str)\n",
    "  info['id_cliente_safra_ref'] = info['id_cliente'].astype(str) + '_' + info['safra_ref'].astype(str)\n",
    "  pagamentos['coherent'] = np.where(pagamentos['id_cliente_safra_ref'].isin(info['id_cliente_safra_ref']), 1, 0)\n",
    "\n",
    "  # Chi-square test to determine if the fraud is independent of the coherent column\n",
    "  from scipy.stats import chi2_contingency\n",
    "  contingency_table = pd.crosstab(pagamentos['fraud'], pagamentos['coherent'])\n",
    "  stat, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "  if p < 0.05:\n",
    "    print('The fraud is dependent of the data in pagamentos where its key does not appear in the info table.\\n' +\n",
    "          'This data should be kept in the pagamentos table')\n",
    "  else:\n",
    "    print('The fraud is independent of the data in pagamentos where its key does not appear in the info table\\n' +\n",
    "          'This data can be removed from the pagamentos table')\n",
    "  return p < 0.05\n",
    "\n",
    "if not is_fraud_dependent_of_the_data_exclusive_to_pagamentos_table(base_info_date, base_pagamentos_date):\n",
    "  def clean_pagamentos_table(info, pagamentos):\n",
    "    # Create a DataFrame that represents the primary key of base_info\n",
    "    base_info_keys = base_info_date[['id_cliente', 'safra_ref']]\n",
    "\n",
    "    # Merge with base_pagamentos, keeping only the records with matching keys\n",
    "    base_pagamentos_coherent = pd.merge(base_pagamentos_date, base_info_keys, on=['id_cliente', 'safra_ref'], how='inner')\n",
    "\n",
    "    # Count the number of excluded rows\n",
    "    excluded_rows = len(base_pagamentos_date) - len(base_pagamentos_coherent)\n",
    "    print(f'Number of excluded rows: {excluded_rows}')\n",
    "    print(f'Percentage of excluded rows: {excluded_rows / len(base_pagamentos_date) * 100:.2f}%')\n",
    "\n",
    "    # Save the coherented DataFrame to a new CSV file\n",
    "    # base_pagamentos_coherent.to_csv('base_pagamentos_desenvolvimento_coherent.csv', index=False)\n",
    "\n",
    "    print('The pagamentos table was cleaned successfully')\n",
    "    return base_pagamentos_coherent\n",
    "  base_pagamentos_date = clean_pagamentos_table(base_info_date, base_pagamentos_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a gaussian distribution of late payments for payments within -20 and 20 days of delay\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(base_pagamentos_date[(base_pagamentos_date['late_payment'] >= -20) & (base_pagamentos_date['late_payment'] <= 20)]['late_payment'], bins=np.arange(-20.5, 20.5, 1), kde=True, log_scale=(False, True))\n",
    "plt.title('Late payments')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info_date['safra_ref'].value_counts().sort_index().plot(kind='bar', figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clientes in base_info but not in base_pagamentos: 88\n",
      "Percentage of clientes in base_info but not in base_pagamentos: 6.59%\n",
      "\n",
      "Number of clientes in base_pagamentos but not in base_info: 0\n",
      "Percentage of clientes in base_pagamentos but not in base_info: 0.00%\n",
      "\n",
      "Percentage of transactions marked as fraudulent: 5.79%\n",
      "Percentage of clients marked as fraudulent at least once: 44.63%\n",
      "\n",
      "Number of clients: 1248\n",
      "\n",
      "Statistics of the number of transactions per client:\n",
      "count    1248.000000\n",
      "mean       62.030449\n",
      "std        94.393904\n",
      "min         1.000000\n",
      "25%         5.000000\n",
      "50%        28.000000\n",
      "75%        90.000000\n",
      "max      1151.000000\n",
      "dtype: float64\n",
      "\n",
      "Statistics of the number of transactions per fraudulent client:\n",
      "count     557.000000\n",
      "mean       87.517056\n",
      "std       117.620756\n",
      "min         1.000000\n",
      "25%        12.000000\n",
      "50%        59.000000\n",
      "75%       116.000000\n",
      "max      1151.000000\n",
      "Name: transacoes, dtype: float64\n",
      "\n",
      "Statistics of the number of fraudulent transactions per fraudulent client:\n",
      "count    557.000000\n",
      "mean       8.044883\n",
      "std       21.024304\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        3.000000\n",
      "75%        6.000000\n",
      "max      293.000000\n",
      "dtype: float64\n",
      "\n",
      "Percentage of the first transaction that is fraudulent: 8.73%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clientes aparecem em base_info_date mas não em base_pagamentos_date\n",
    "clientes_info = base_info_date['id_cliente'].unique()\n",
    "clientes_pagamentos = base_pagamentos_date['id_cliente'].unique()\n",
    "clientes_info_not_in_pagamentos = [cliente for cliente in clientes_info if cliente not in clientes_pagamentos]\n",
    "clientes_pagamentos_not_in_info = [cliente for cliente in clientes_pagamentos if cliente not in clientes_info]\n",
    "print(f'Number of clientes in base_info but not in base_pagamentos: {len(clientes_info_not_in_pagamentos)}')\n",
    "print(f'Percentage of clientes in base_info but not in base_pagamentos: {len(clientes_info_not_in_pagamentos) / len(clientes_info) * 100:.2f}%\\n')\n",
    "print(f'Number of clientes in base_pagamentos but not in base_info: {len(clientes_pagamentos_not_in_info)}')\n",
    "print(f'Percentage of clientes in base_pagamentos but not in base_info: {len(clientes_pagamentos_not_in_info) / len(clientes_pagamentos) * 100:.2f}%\\n')\n",
    "\n",
    "# porcentage of transactions marked as fraudulent\n",
    "print(f'Percentage of transactions marked as fraudulent: {base_pagamentos_date[\"fraud\"].sum() / len(base_pagamentos_date) * 100:.2f}%')\n",
    "\n",
    "# porcentage of clients marked as fraudulent\n",
    "print(f'Percentage of clients marked as fraudulent at least once: {base_pagamentos_date.groupby(\"id_cliente\")[\"fraud\"].any().sum() / len(base_pagamentos_date[\"id_cliente\"].unique()) * 100:.2f}%\\n')\n",
    "\n",
    "# quantidade de clientes\n",
    "print(f'Number of clients: {len(base_pagamentos_date[\"id_cliente\"].unique())}\\n')\n",
    "\n",
    "# quantas transações cada cliente tem em base_pagamentos_date\n",
    "transacoes_por_cliente = base_pagamentos_date.groupby('id_cliente').size().sort_values(ascending=False)\n",
    "print(f'Statistics of the number of transactions per client:\\n{transacoes_por_cliente.describe()}\\n')\n",
    "\n",
    "# quantas transações cada cliente fraudulento tem em base_pagamentos_date\n",
    "transacoes_por_cliente_fraudulento = base_pagamentos_date.groupby('id_cliente').agg({'fraud': 'any', 'id_cliente': 'count'})\n",
    "transacoes_por_cliente_fraudulento.columns = ['fraud', 'transacoes']\n",
    "transacoes_por_cliente_fraudulento = transacoes_por_cliente_fraudulento[transacoes_por_cliente_fraudulento['fraud'] == 1]['transacoes'].sort_values(ascending=False)\n",
    "print(f'Statistics of the number of transactions per fraudulent client:\\n{transacoes_por_cliente_fraudulento.describe()}\\n')\n",
    "\n",
    "# quantas transações fraudulentas cada cliente fraudulento tem em base_pagamentos_date\n",
    "fraudulent_transacoes_por_cliente_fraudulento = base_pagamentos_date[base_pagamentos_date['fraud'] == 1].groupby('id_cliente').size().sort_values(ascending=False)\n",
    "print(f'Statistics of the number of fraudulent transactions per fraudulent client:\\n{fraudulent_transacoes_por_cliente_fraudulento.describe()}\\n')\n",
    "\n",
    "# porcentage of the first transaction of each client that is fraudulent\n",
    "print(f\"Percentage of the first transaction that is fraudulent: {base_pagamentos_date.sort_values(['id_cliente', 'data_emissao_documento']).drop_duplicates('id_cliente').fraud.mean() * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from create_sheets import create_spreadsheet, upload_csv_to_sheet\n",
    "\n",
    "# spreadsheet_id = create_spreadsheet('Test Spreadsheet')\n",
    "# upload_csv_to_sheet(spreadsheet_id, 'base_pagamentos_sorted_id_emissao_pagamento.csv', 'Sheet1')\n",
    "# upload_csv_to_sheet(spreadsheet_id, 'base_pagamentos_drop_dupl.csv', 'Sheet2')\n",
    "# # print the spreadsheet link\n",
    "# print(f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grafico de linha do 50% percentile de transacoes por cliente, transacoes por cliente fraudulento e transacoes fraudulentas por cliente fraudulento\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# def concatenate_descriptions(dataframes, names):\n",
    "#     descriptions = []\n",
    "    \n",
    "#     for df, name in zip(dataframes, names):\n",
    "#         description = df.describe().to_frame().T\n",
    "#         description.index = [name]\n",
    "#         descriptions.append(description)\n",
    "    \n",
    "#     concatenated_descriptions = pd.concat(descriptions).T\n",
    "#     return concatenated_descriptions\n",
    "\n",
    "# dataframes = [transacoes_por_cliente, transacoes_por_cliente_fraudulento, fraudulent_transacoes_por_cliente_fraudulento]\n",
    "# names = ['transacoes_por_cliente', 'transacoes_por_cliente_fraudulento', 'fraudulent_transacoes_por_cliente_fraudulento']\n",
    "# transacoes_descriptions = concatenate_descriptions(dataframes, names)\n",
    "\n",
    "# # plot the line graph\n",
    "# sns.lineplot(data=transacoes_descriptions.loc[['25%', '50%', '75%'], :], dashes=False)\n",
    "# plt.title('Number of transactions per client')\n",
    "# plt.xlabel('Percentile')\n",
    "# plt.ylabel('Number of transactions')\n",
    "# plt.show()\n",
    "\n",
    "# transacoes_descriptions.head(10)\n",
    "# # base_pagamentos_date.groupby(\"id_cliente\")[\"fraud\"].sum()\n",
    "# # base_pagamentos_date[base_pagamentos_date[\"id_cliente\"] == 209314261782935157                             ]['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
